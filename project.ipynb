{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "This chatbot should answer scientific news from the year 2024. The data source is the Wikipedia page 2024_in_science which contains a short desciption for scientific new from that year. It's a good data source for this project since the used LLM model includes only data before 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554467a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c634f6b3",
   "metadata": {},
   "source": [
    "### Download \n",
    "\n",
    "Dataset is from Wikipedia: https://en.wikipedia.org/wiki/2024_in_science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full request URL: https://en.wikipedia.org/w/api.php?action=query&prop=extracts&titles=2024_in_science&explaintext=1&formatversion=2&format=json\n"
     ]
    }
   ],
   "source": [
    "title = \"2024_in_science\"\n",
    "params = {\n",
    "    \"action\": \"query\", \n",
    "    \"prop\": \"extracts\",\n",
    "    \"titles\": title,\n",
    "    \"explaintext\": 1,\n",
    "    \"formatversion\": 2,\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "resp = requests.get(\"https://en.wikipedia.org/w/api.php\", params=params)\n",
    "print(\"Full request URL:\", resp.url)\n",
    "response_dict = resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70312cd",
   "metadata": {},
   "source": [
    "Dataset has headins which start with \"==\", empty lines and a description of the data in the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff4098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     The following scientific events occurred in 2024.\n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                          == Events ==\n",
      "4                                                      \n",
      "5                                                      \n",
      "6                                       === January ===\n",
      "7     2 January – The Japan Meteorological Agency (J...\n",
      "8     3 January – The first functional semiconductor...\n",
      "9     4 January – A review indicates digital rectal ...\n",
      "10                                            5 January\n",
      "11    Scientists report that newborn galaxies in the...\n",
      "12    An analysis of sugar-sweetened beverage (SSB) ...\n",
      "13                                            9 January\n",
      "14    Scientists report studies that seem to support...\n",
      "15    A group of scientists from around the globe ha...\n",
      "16    Researchers have discovered a new phase of mat...\n",
      "17    A study of proteins in cerebrospinal fluid ind...\n",
      "18    A study finds seaweed farming could be set up ...\n",
      "19                                           10 January\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load page text into a dataframe\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = response_dict['query']['pages'][0]['extract'].split(\"\\n\")\n",
    "\n",
    "file_name_unprocessed = \"data/{}_unprocessed.csv\".format(title)\n",
    "df.to_csv(file_name_unprocessed)\n",
    "\n",
    "print(df['text'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27a43b",
   "metadata": {},
   "source": [
    "At the end of the table there information \"See also\" and \"References\" which are not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff16bae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342                                          27 December\n",
      "343    A new technique for lifelike facial expression...\n",
      "344    Carbon in outer space is shown to travel on a ...\n",
      "345                                                     \n",
      "346                                                     \n",
      "347                                       == See also ==\n",
      "348                                                     \n",
      "349                                  2024 in spaceflight\n",
      "350                              Category:Science events\n",
      "351                           Category:Science timelines\n",
      "352                        List of emerging technologies\n",
      "353                             List of years in science\n",
      "354                                                     \n",
      "355                                                     \n",
      "356                                     == References ==\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc50eb",
   "metadata": {},
   "source": [
    "Save the unprocessed data so it doesn't have to be downloaded ever time it's worked on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f70be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     The following scientific events occurred in 2024.\n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                          == Events ==\n",
      "4                                                      \n",
      "5                                                      \n",
      "6                                       === January ===\n",
      "7     2 January – The Japan Meteorological Agency (J...\n",
      "8     3 January – The first functional semiconductor...\n",
      "9     4 January – A review indicates digital rectal ...\n",
      "10                                            5 January\n",
      "11    Scientists report that newborn galaxies in the...\n",
      "12    An analysis of sugar-sweetened beverage (SSB) ...\n",
      "13                                            9 January\n",
      "14    Scientists report studies that seem to support...\n",
      "15    A group of scientists from around the globe ha...\n",
      "16    Researchers have discovered a new phase of mat...\n",
      "17    A study of proteins in cerebrospinal fluid ind...\n",
      "18    A study finds seaweed farming could be set up ...\n",
      "19                                           10 January\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read the file earlier saved\n",
    "df = pd.read_csv(file_name_unprocessed, index_col=0, keep_default_na=False)\n",
    "print(df['text'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d8eac8",
   "metadata": {},
   "source": [
    "### Preprocessing data\n",
    "\n",
    "- remove empty lines\n",
    "- Remove all rows at the end after the heading \"See also\"\n",
    "- remove the first line which just explains this data is from 2024\n",
    "- remove headings (they start with \"==\")\n",
    "- add dates to every row with data and remove rows that only have a date\n",
    "- add the year to all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0945060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2 January – The Japan Meteorological Agency (J...\n",
      "1     3 January – The first functional semiconductor...\n",
      "2     4 January – A review indicates digital rectal ...\n",
      "3                                             5 January\n",
      "4     Scientists report that newborn galaxies in the...\n",
      "5     An analysis of sugar-sweetened beverage (SSB) ...\n",
      "6                                             9 January\n",
      "7     Scientists report studies that seem to support...\n",
      "8     A group of scientists from around the globe ha...\n",
      "9     Researchers have discovered a new phase of mat...\n",
      "10    A study of proteins in cerebrospinal fluid ind...\n",
      "11    A study finds seaweed farming could be set up ...\n",
      "12                                           10 January\n",
      "13    Chemists report studies finding that long-chai...\n",
      "14    Scientists report the extinction of Gigantopit...\n",
      "15                                           11 January\n",
      "16    Biologists report the discovery of the oldest ...\n",
      "17    Scientists report the discovery of Tyrannosaur...\n",
      "18    A study of the Caatinga region in Brazil finds...\n",
      "19    A graphene-based implant on the surface of mou...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# remove empty lines\n",
    "df = df[df['text'] != \"\"]\n",
    "\n",
    "# remove content after \"See also\" with is not relevant for the task\n",
    "ref_index = df[df['text'] == '== See also =='].index\n",
    "df = df.drop(df.index[ref_index[0]:])\n",
    "\n",
    "# remove first line\n",
    "df = df.drop(df.index[0])\n",
    "\n",
    "# remove headings\n",
    "df = df[~df['text'].str.contains('==')]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df['text'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6653a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2024 2 January – The Japan Meteorological Agen...\n",
      "1     2024 3 January – The first functional semicond...\n",
      "2     2024 4 January – A review indicates digital re...\n",
      "3     2024 5 January – Scientists report that newbor...\n",
      "4     2024 5 January – An analysis of sugar-sweetene...\n",
      "5     2024 9 January – Scientists report studies tha...\n",
      "6     2024 9 January – A group of scientists from ar...\n",
      "7     2024 9 January – Researchers have discovered a...\n",
      "8     2024 9 January – A study of proteins in cerebr...\n",
      "9     2024 9 January – A study finds seaweed farming...\n",
      "10    2024 10 January – Chemists report studies find...\n",
      "11    2024 10 January – Scientists report the extinc...\n",
      "12    2024 11 January – Biologists report the discov...\n",
      "13    2024 11 January – Scientists report the discov...\n",
      "14    2024 11 January – A study of the Caatinga regi...\n",
      "15    2024 11 January – A graphene-based implant on ...\n",
      "16    2024 11 January – A review of genetic data fro...\n",
      "17    2024 11 January – The Upano Valley sites are r...\n",
      "18    2024 11 January – A study presents results of ...\n",
      "19    2024 12 January – Global warming: 2023 is conf...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "# a bit modified version of the algorthm used in the course\n",
    "# processes data so that every row has a corresponding date included\n",
    "\n",
    "# In some cases dates are used as headings instead of being part of the\n",
    "# text sample; adjust so dated text samples start with dates\n",
    "prefix = \"\"\n",
    "for (i, row) in df.iterrows():\n",
    "    # If the row already has \" - \", it already has the needed date prefix    \n",
    "    if \" – \" not in row[\"text\"][0:15]:\n",
    "        try:\n",
    "            # If the row's text is a date, set it as the new prefix\n",
    "            parse(row[\"text\"])\n",
    "            prefix = row[\"text\"]\n",
    "        except:\n",
    "            # If the row's text isn't a date, add the prefix\n",
    "            row[\"text\"] = prefix + \" – \" + row[\"text\"]\n",
    "df = df[df[\"text\"].str.contains(\" – \")].reset_index(drop=True)\n",
    "\n",
    "df['text'] = '2024 ' + df['text']\n",
    "\n",
    "print(df['text'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a76639",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_processed = \"data/{}.csv\".format(title)\n",
    "df.to_csv(file_name_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16cd3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name_processed, index_col=0)\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "\n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "\n",
    "file_name_embeddings = \"data/{}_embeddings.csv\".format(title)\n",
    "df.to_csv(file_name_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb6e29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00503582, -0.00736004, -0.02706596, -0.01150866, -0.0002343 ,\n",
       "       -0.00426108, -0.01763161,  0.00950933, -0.01009663, -0.02619126])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_name_embeddings, index_col=0)\n",
    "df[\"embeddings\"] = df[\"embeddings\"].apply(eval).apply(np.array)\n",
    "df[\"embeddings\"][0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c8e80",
   "metadata": {},
   "source": [
    "### Create functions\n",
    "\n",
    "They encapsulate the prompt generation and asking questions to the model.\n",
    "\n",
    "- load our processed data with embeddings from file\n",
    "- create embedding from question\n",
    "- calculate distances to the embeddings of the data\n",
    "- use the best fitting data rows as context for the prompt\n",
    "- let the model process the prompt and return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5ff9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"2024_in_science\"\n",
    "file_name_embeddings = \"data/2024_in_science_embeddings.csv\".format(title)\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def load_df(path):\n",
    "    \"\"\"Loads the dataframe including the embeddings from file\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"embeddings\"] = df[\"embeddings\"].apply(eval).apply(np.array)\n",
    "    return df\n",
    "\n",
    "def create_embeddings(question):\n",
    "    \"\"\"Creates the embeddings of a question\"\"\"\n",
    "    return get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "def create_distances(df, question_embeddings):\n",
    "    \"\"\"Calculates the distances of a questions embedding to the rows in the dataframe\"\"\"\n",
    "    return distances_from_embeddings(question_embeddings, df[\"embeddings\"].tolist(), distance_metric=\"cosine\")\n",
    "\n",
    "def create_prompt(question, context=None):\n",
    "    \"\"\"Creates a prompt from a question, if a context is given it adds the context to the prompt.\"\"\"\n",
    "    if context != None:\n",
    "        prompt_template = \"\"\"\n",
    "        Answer the question based on the context below, and if the \n",
    "        question can't be answered based on the context, say \n",
    "        \"I don't know\"\n",
    "\n",
    "        Context: \n",
    "\n",
    "        {}\n",
    "\n",
    "        ---\n",
    "\n",
    "        Question: {}\n",
    "        Answer:\"\"\"\n",
    "\n",
    "        return prompt_template.format(context, question)\n",
    "    else:\n",
    "        prompt_template = \"\"\"\n",
    "        Answer the question and if the question can't be answered from you, say \n",
    "        \"I don't know\"\n",
    "\n",
    "        ---\n",
    "\n",
    "        Question: {}\n",
    "        Answer:\"\"\"\n",
    "\n",
    "        return prompt_template.format(question)\n",
    "    \n",
    "\n",
    "def create_context(df):\n",
    "    \"\"\"Creates a context from a dataframe by including the best matching rows\"\"\"\n",
    "    context = \"\"\n",
    "    for row in df['text'].head(10):\n",
    "        context += \"###\\n\" + row + '\\n'\n",
    "    return context\n",
    "\n",
    "def process_prompt(prompt):\n",
    "    \"\"\"Process the prompt with the model and return the answer is the call is successfull.\n",
    "    In case an error occurs, the error is printed and None is returned\"\"\"\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=150\n",
    "        )\n",
    "    except openai.APIError as e:\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "        return None\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "        return None\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "        return None\n",
    "\n",
    "    answer = response[\"choices\"][0][\"text\"].strip()\n",
    "    return answer\n",
    "\n",
    "def answer_question(question, enable_context=True, save_distances=False, print_prompt=False):\n",
    "    \"\"\"Generate a prompt from the given answer, let the model process it and return the answer.\n",
    "\n",
    "    Keyword arguments:\n",
    "    question -- the question to ask the model\n",
    "    enable_context -- if the context from the dataset should be added\n",
    "    save_distances -- if the dataframe including the distances for the question should be saved\n",
    "    print_prompt -- if the prompt should be printed (for debugging)\n",
    "    \"\"\"\n",
    "    df = load_df(file_name_embeddings)\n",
    "    embeddings_question = create_embeddings(question)\n",
    "    df['distances'] = create_distances(df, embeddings_question)\n",
    "    df = df.sort_values(by=\"distances\")\n",
    "    \n",
    "    if save_distances:\n",
    "        filename = \"data/{}_question_{}.csv\".format(title, question[0:20])\n",
    "        df.to_csv(filename)\n",
    "\n",
    "    context = None\n",
    "    if (enable_context):\n",
    "        context = create_context(df)\n",
    "    \n",
    "    prompt = create_prompt(question, context)\n",
    "\n",
    "    if (print_prompt):\n",
    "        print(prompt)\n",
    " \n",
    "    answer = process_prompt(prompt)\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "Demonstation of the performace with embeddings. There are two questions which are asked to the model. First a prompt without the data from our custom dataset are tried, then a prompt with the best matching rows of the dataset. The prompt is printed so it can be checked that the correct prompts are used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8c51b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Answer the question and if the question can't be answered from you, say \n",
      "        \"I don't know\"\n",
      "\n",
      "        ---\n",
      "\n",
      "        Question: Who reported the discovery of TOI-715 b? When was it announced?\n",
      "        Answer:\n",
      "\n",
      "\n",
      "Question: Who reported the discovery of TOI-715 b? When was it announced?\n",
      "Answer: Mayor et al. made the discovery in 2021 and it was publicly announced on July 29, 2021.\n"
     ]
    }
   ],
   "source": [
    "question = \"Who reported the discovery of TOI-715 b? When was it announced?\"\n",
    "answer = answer_question(question, enable_context=False, print_prompt=True)\n",
    "print(\"\\n\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Answer the question based on the context below, and if the \n",
      "        question can't be answered based on the context, say \n",
      "        \"I don't know\"\n",
      "\n",
      "        Context: \n",
      "\n",
      "        ###\n",
      "2024 31 January – NASA reports the discovery of a super-Earth called TOI-715 b, located in the habitable zone of a red dwarf star about 137 light-years away.\n",
      "###\n",
      "2024 12 August – An Earth-sized, ultra-short period exoplanet called TOI-6255b is found to be undergoing extreme tidal distortion, caused by the close proximity of its parent star. This has resulted in an egg-shaped planet, likely to be destroyed within 400 million years.\n",
      "###\n",
      "2024 15 May – Astronomers report an overview of preliminary analytical studies on returned samples of asteroid 101955 Bennu by the OSIRIS-REx mission.\n",
      "###\n",
      "2024 15 July – Scientists announce the discovery of a lunar cave, approximately 250 miles (400 km) from Apollo 11's landing site.\n",
      "###\n",
      "2024 11 October – Astronomers observe the \"inside-out\" growth of NGC 1549 by using the James Webb Space Telescope. Researchers assume that it could solve the mystery of how these complex structures are being formed from gas clouds.\n",
      "###\n",
      "2024 29 April – Timothy A. Coleman, with the University of Alabama in Huntsville, Richard L. Thompson with the NOAA Storm Prediction Center, and Dr. Gregory S. Forbes, a retired meteorologist from The Weather Channel publish an article to the Journal of Applied Meteorology and Climatology stating, \"it is apparent that the perceived shift in tornado activity from the traditional tornado alley in the Great Plains to the eastern U.S. is indeed real\".\n",
      "###\n",
      "2024 16 August – The Planetary Habitability Laboratory publishes a report concluding that the Wow! signal was likely been caused by a rare astrophysical event, the sudden brightening of a cold molecular cloud triggered by a stellar emission.\n",
      "###\n",
      "2024 17 October – Scientists observe a black hole corona using NASA's Imaging X-ray Polarimetry Explorer, and determine its shape for the first time.\n",
      "###\n",
      "2024 2 October – Scientists detect a new jet of carbon monoxide (CO) and previously unseen jets of carbon dioxide (CO2) gas on Centaur 29P by using the James Webb Space Telescope's Near-Infrared Spectrograph.\n",
      "###\n",
      "2024 10 October – Scientists use a high-level machine learning model \"SHBoost\", to process data and estimate precise stellar properties for 217 million stars observed by the Gaia mission.\n",
      "\n",
      "\n",
      "        ---\n",
      "\n",
      "        Question: Who reported the discovery of TOI-715 b? When was it announced?\n",
      "        Answer:\n",
      "\n",
      "\n",
      "Question: Who reported the discovery of TOI-715 b? When was it announced?\n",
      "Answer: NASA and it was announced on January 31, 2024.\n"
     ]
    }
   ],
   "source": [
    "answer = answer_question(question, enable_context=True, print_prompt=True)\n",
    "print(\"\\n\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171135c",
   "metadata": {},
   "source": [
    "#### Results for Question 1\n",
    "\n",
    "- Model without context: Answered with hallucinated information that can't be verified in the internet.\n",
    "- Model with context: Answered correct with the information from the Wikipedia data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Answer the question and if the question can't be answered from you, say \n",
      "        \"I don't know\"\n",
      "\n",
      "        ---\n",
      "\n",
      "        Question: What is the luminous astronomical object ever discovered? When was it discovered?\n",
      "        Answer:\n",
      "\n",
      "Question: What is the luminous astronomical object ever discovered? When was it discovered?\n",
      "Answer: The most luminous astronomical object discovered so far is a quasar known as J1342+0928, discovered in 2017. However, it is possible that there are even more luminous objects yet to be discovered in the universe.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the luminous astronomical object ever discovered? When was it discovered?\"\n",
    "answer = answer_question(question, enable_context=False, print_prompt=True)\n",
    "print(\"\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdff259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Answer the question based on the context below, and if the \n",
      "        question can't be answered based on the context, say \n",
      "        \"I don't know\"\n",
      "\n",
      "        Context: \n",
      "\n",
      "        ###\n",
      "2024 19 February – Astronomers announce the most luminous object ever discovered, quasar QSO J0529-4351, located 12 billion light-years away in the constellation Pictor.\n",
      "###\n",
      "2024 18 September – The largest known pair of astrophysical jets is discovered within the radio galaxy Porphyrion, extending 23 million light-years from end to end. This surpasses Alcyoneus, the previous record holder at 16 million light-years.\n",
      "###\n",
      "2024 17 December – Zhúlóng (\"Torch Dragon\"), discovered by the James Webb Space Telescope, is reported as being the most distant known spiral galaxy ever found, seen as it appeared just 1.1 billion years after the Big Bang.\n",
      "###\n",
      "2024 11 July – Using the Hubble Space Telescope, scientists resolve the 3D velocity dispersion profile of a dwarf galaxy for the first time, helping to uncover its dark matter distribution.\n",
      "###\n",
      "2024 30 May – NASA reports that the James Webb Space Telescope has discovered JADES-GS-z14-0, the most distant known galaxy, which existed only 290 million years after the Big Bang. Its redshift of 14.32 exceeds the previous record of 13.2, set by JADES-GS-z13-0.\n",
      "###\n",
      "2024 11 October – Astronomers observe the \"inside-out\" growth of NGC 1549 by using the James Webb Space Telescope. Researchers assume that it could solve the mystery of how these complex structures are being formed from gas clouds.\n",
      "###\n",
      "2024 17 October – Scientists observe a black hole corona using NASA's Imaging X-ray Polarimetry Explorer, and determine its shape for the first time.\n",
      "###\n",
      "2024 21 November – The first close-up image of a star outside the Milky Way is reported, using the European Southern Observatory's Very Large Telescope Interferometer. The star WOH G64 is located in the Large Magellanic Cloud, about 160,000 light years away, and is shown to be surrounded by a torus-shaped cloud.\n",
      "###\n",
      "2024 31 January – NASA reports the discovery of a super-Earth called TOI-715 b, located in the habitable zone of a red dwarf star about 137 light-years away.\n",
      "###\n",
      "2024 19 September – A recently discovered near-Earth object called 2024 PT5 is calculated to become a \"mini-moon\" with a temporary orbit around Earth from September 29 until November 25. It will return in the year 2055.\n",
      "\n",
      "\n",
      "        ---\n",
      "\n",
      "        Question: What is the luminous astronomical object ever discovered? When was it discovered?\n",
      "        Answer:\n",
      "\n",
      "Question: What is the luminous astronomical object ever discovered? When was it discovered?\n",
      "Answer: quasar QSO J0529-4351, February 19, 2024\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the luminous astronomical object ever discovered? When was it discovered?\"\n",
    "answer = answer_question(question, enable_context=True, print_prompt=True)\n",
    "print(\"\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a97a61",
   "metadata": {},
   "source": [
    "#### Results for Question 2\n",
    "\n",
    "- Model without context: Answered with outdated information or with \"don't know\". The answer shown here could be outdated since the quasar is really a very luminous object, though I couldn't veryfy it once was the most luminous know object.\n",
    "- Model with context: Answered correct with the information from the Wikipedia data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e39f3",
   "metadata": {},
   "source": [
    "## Control question\n",
    "\n",
    "Control question should show that the model can answer questions about topic which where know at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2790e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Answer the question and if the question can't be answered from you, say \n",
      "        \"I don't know\"\n",
      "\n",
      "        ---\n",
      "\n",
      "        Question: When has NASA declared the Mars rover Opportunity has ended its mission?\n",
      "        Answer:\n",
      "\n",
      "\n",
      "Question: When has NASA declared the Mars rover Opportunity has ended its mission?\n",
      "Answer: NASA declared the Mars rover Opportunity's mission ended on February 13, 2019.\n"
     ]
    }
   ],
   "source": [
    "question = \"When has NASA declared the Mars rover Opportunity has ended its mission?\"\n",
    "\n",
    "answer = answer_question(question, enable_context=False, print_prompt=True)\n",
    "print(\"\\n\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a82e50",
   "metadata": {},
   "source": [
    "The answer is correct according to Wikipedia 2019_in_science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb45623",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2809a8e",
   "metadata": {},
   "source": [
    "Chatbot for scientific news in 2024. It don't adds the last question-answer to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "426eaf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot for scientific news in 2024\n",
      "\n",
      "\n",
      "Question: Was a new species discoverd in 2024?\n",
      "Answer: Yes, many new species were discovered in 2024. Some examples include the new species of mussel named Vadumodiolus teredinicola, the new species of jellyfish named Santjordia pagesi, and the new species of giant snake, the northern green anaconda (Eunectes akayima).\n",
      "\n",
      "Question: What events happened in 2024 with AI topics?\n",
      "Answer: Promising innovations relating to global challenges are reported: LAION releases a first version of BUD-E, a fully open source voice assistant (8 Feb), Minesto's Dragon 12 underwater tidal kite turbines are demonstrated successfully, connected to the Faroe Island's power grid (11 Feb), rice grains as scaffolds containing cultured animal cells are demonstrated (14 Feb), an automatic waste sorting system (ZenRobotics 4.0) that can distinguish between over 500 waste categories is released (15 Feb), researchers describe an AI ecosystem interface of foundation models connected to many APIs as specialized subtask-solvers (16 Feb), precision fermentation-derived beta-lactoglobulin is released as a substitute for whey protein amid growth of a nascent animal-free\n",
      "\n",
      "Question: Any news for HIV in 2024?\n",
      "Answer: The removal of HIV from infected cells using CRISPR gene editing technology is reported on 20 March 2024.\n",
      "\n",
      "Question: What companies will work for the Artemis mission? When will the project start?\n",
      "Answer: Intuitive Machines, Lunar Outpost, and Venturi Astrolab. The project will start from 2030 onwards.\n",
      "\n",
      "Question: When was the first mouse model with a human immune system shown?\n",
      "Answer: 5 July 2024\n",
      "\n",
      "Question: How many measles cases were reported in 2023? Is the number increasing or decreasing over the last years?\n",
      "Answer: The context does not provide enough information to answer this question.\n",
      "\n",
      "Question: How many measles cases were reported in 2023?\n",
      "Answer: 10.3 million\n",
      "\n",
      "Question: Any news from Osaka University in 2024?\n",
      "Answer: A new technique for lifelike facial expressions on androids is reported by Osaka University, using waveform movements to dynamically express mood states, such as \"excited\" or \"sleepy\".\n",
      "\n",
      "Question: exit\n",
      "Answer: I don't know.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot for scientific news in 2024\\n\")\n",
    "question = None\n",
    "\n",
    "while question != \"exit\":\n",
    "    question = input(\"Question: \")\n",
    "    answer = answer_question(question, enable_context=True, print_prompt=False)\n",
    "    print(\"\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06b52c",
   "metadata": {},
   "source": [
    "### Try the chatbot without context\n",
    "\n",
    "To see how the model answers without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8966482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot with the base model without context\n",
      "\n",
      "Please ask me questions. Stop the conversation with \"exit\"\n",
      "\n",
      "\n",
      "Question: Who are you?\n",
      "Answer: We are the *Bot Squad*; ask us anything!\n",
      "\n",
      "Question: Are you GPT 3.5?\n",
      "Answer: \"(I'm) not GPT 3.5.\n",
      "\n",
      "Question: Who are you then?\n",
      "Answer: My name is GPT-3. I am OpenAI's latest artificial intelligence language model. I have been trained on a large dataset of texts and am capable of generating human-like text responses to various prompts. Is there anything else you would like to know?\n",
      "\n",
      "Question: Who are you and when was your training finished?\n",
      "Answer: I am AI agent assistant named Agent Assistant Martury. My training was finished on October/25/2019 by Dr Ma Cheng. \n",
      "        \n",
      "        (Alternative that includes the year as well:)\n",
      "        \n",
      "        Answer: I am AI agent assistant named Agent Assistant Martury. My training was finished on October 25, 2019 by Dr Ma Cheng.\n",
      "\n",
      "Question: Could it be that your answers are meant to be parsed?\n",
      "Answer: I don't know\n",
      "\n",
      "Question: Who are you and when was your training finished?\n",
      "Answer: My name is ElectricTutor. I am a computer program designed to answer questions. As an AI, I do not have a specific training completion date as my learning and development is ongoing.\n",
      "\n",
      "Question: You are Doctor Who, aren't you?\n",
      "Answer: I don't know\n",
      "\n",
      "Question: Do you know any event from 2022?\n",
      "Answer: I don't know.\n",
      "\n",
      "Question: Any news from 2021?\n",
      "Answer: No, I don't keep up with current events.\n",
      "\n",
      "Question: What happened in 2021?\n",
      "Answer: I don't know\n",
      "\n",
      "Question: What happened in 2020?\n",
      "Answer: I don't know\n",
      "    */\n",
      "    static question1() {\n",
      "        return loadJson(\"\", \"q1\");\n",
      "    }\n",
      "\n",
      "      /*\n",
      "        Exercise 2 \n",
      "        \n",
      "        Given a string str, write a method that will \n",
      "        return the string made up of its last char and \n",
      "        then the first char and so on.\n",
      "\n",
      "        ---\n",
      "\n",
      "        Parameters: str\n",
      "        Returns: str\n",
      "    */\n",
      "    static flipTheString(str) {\n",
      "        var strFlip = '';\n",
      "        var temp = ''\n",
      "        for (var i = (str.length - 1); i>=0; i=i-2) {\n",
      "            temp = str[i];\n",
      "            if((i-1)>= 0) {\n",
      "                temp = temp + str[i-1];\n",
      "            }\n",
      "\n",
      "Question: Why do you answer sometime with code snippets?\n",
      "Answer: I answer sometimes with code snippets when it is the best way to answer the\n",
      "        question. If the question requires a complex solution or contains code that\n",
      "        requires a visual aid, then providing snippets in the answer can be more helpful\n",
      "        than giving just a verbal explanation. It also helps to demonstrate the thought\n",
      "        process and can make the answer easier to understand for others reading it.\n",
      "\n",
      "Question: It looks like you answer with snippets from trainingsdata that is not related to the question.\n",
      "Answer: I don't know\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot with the base model without context\\n\")\n",
    "print(\"Please ask me questions. Stop the conversation with \\\"exit\\\"\\n\")\n",
    "question = None\n",
    "\n",
    "while True:\n",
    "    question = input(\"Question: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    answer = answer_question(question, enable_context=False, print_prompt=False)\n",
    "    print(\"\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f10e1",
   "metadata": {},
   "source": [
    "#### Reduced prompt with a kind of sytem prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "492e3cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot with the base model without context, reduced prompt\n",
      "\n",
      "Please ask me questions. Stop the conversation with \"exit\"\n",
      "\n",
      "\n",
      "Question: Who are you?\n",
      "Answer: I am an AI chatbot assistant designed to help answer questions and assist with tasks. I am always learning and improving to better serve my users. Is there something specific you would like to know or need help with?\n",
      "\n",
      "Question: Is a hedgehog a mammal?\n",
      "Answer: Yes, a hedgehog is a mammal. They are small, spiny animals with four legs, fur, and produce milk to feed their young. They also have specialized teeth and internal organs, which are defining characteristics of mammals.\n",
      "\n",
      "Question: Who are you?\n",
      "Answer: I am a chatbot assistant designed to help and provide answers to user's questions.\n",
      "\n",
      "Question: Are you GPT 3.5?\n",
      "Answer: No, I am not GPT 3.5. I am an AI chatbot trained to assist and answer questions to the best of my ability.\n",
      "\n",
      "Question: Who are you and when was your training finished?\n",
      "Answer: I am an AI chatbot designed to assist and provide helpful responses to users. My training is ongoing as I continuously learn and improve my abilities.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot with the base model without context, reduced prompt\\n\")\n",
    "print(\"Please ask me questions. Stop the conversation with \\\"exit\\\"\\n\")\n",
    "question = None\n",
    "\n",
    "while True:\n",
    "    question = input(\"Question: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    prompt = \"You are a helpful chatbot assistand and answer the questions carefully.\\n\\n======\\n\\nQuestion: \" + question + \"\\n\\nAnswer:\"\n",
    "    #print(\"Prompt: \" + prompt + \"\\n\")\n",
    "    answer = process_prompt(prompt)\n",
    "    \n",
    "    print(\"\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5bad998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prompt without system prompt, just question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35a84da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot with the base model without context, mini prompt\n",
      "\n",
      "Please ask me questions. Stop the conversation with \"exit\"\n",
      "\n",
      "\n",
      "Question: Who are you and when was your training finished?\n",
      "Answer: I am an AI digital assistant designed by OpenAI. My training is ongoing and will continue to improve and learn through interactions and feedback from users. There is no set date for when my training will be finished, as I am constantly evolving and adapting to new information and resources.\n",
      "\n",
      "Question: Who are you and when was your training finished?\n",
      "Answer: I am an AI digital assistant designed and created by a team of programmers and engineers. My training has been ongoing since my creation, but I was officially launched and made available for use on [insert launch date here].\n",
      "\n",
      "Question: Who are you and when was your training finished?\n",
      "Answer: I am an AI digital assistant designed and created by a team of developers. My training is an ongoing process as I constantly learn and adapt to new information and interactions with users. However, I was first released in 2013, so that could be considered the \"finished\" stage of my initial training.\n",
      "\n",
      "Question: Are you GPT 3.5?\n",
      "Answer: No, I am not GPT 3.5. I am a AI chatbot designed and created by OpenAI, but I am not a specific version of GPT.\n",
      "\n",
      "Question: Are you GPT 3.5?\n",
      "Answer: No, I am not GPT 3.5. I am an AI chatbot trained to respond to various prompts and questions. GPT 3.5 refers to a specific version of the GPT (Generative Pre-trained Transformer) language model developed by OpenAI. While I may use some similar techniques and algorithms, I am not the same as GPT 3.5.\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot with the base model without context, mini prompt\\n\")\n",
    "print(\"Please ask me questions. Stop the conversation with \\\"exit\\\"\\n\")\n",
    "question = None\n",
    "\n",
    "while True:\n",
    "    question = input(\"Question: \")\n",
    "    if question == \"exit\":\n",
    "        break\n",
    "    prompt = \"Question: \" + question + \"\\n\\nAnswer:\"\n",
    "    #print(\"Prompt: \" + prompt + \"\\n\")\n",
    "    answer = process_prompt(prompt)\n",
    "    \n",
    "    print(\"\\nQuestion: {}\\nAnswer: {}\".format(question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05bc904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
